# file_indexer

- Pre-indexed search vs dynamic search in varying files
- Assume, macOS and Linux
- Docker
- Tokenizer (NLTK word_tokenize on the other hand is based on a TreebankWordTokenizer, see the docs here. It basically tokenizes text like in the Penn Treebank.)
- Reuters Corpus contains 10,788 news documents totaling 1.3 million words (will help with unit tests as well)

# License

This project is covered under the **Apache 2.0 License**.
